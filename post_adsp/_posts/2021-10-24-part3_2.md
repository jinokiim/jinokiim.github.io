---
layout: post
title: Part 3
subtitle: 
gh-repo: jinokiim/jinokiim.github.io
gh-badge: [star, fork, follow]
thumbnail-img: /assets/img/sp/dspthumb.png
cover-img: /assets/img/sp/dspbg.jpeg
tags: [ADsP]
comments: true
---  


# 데이터 분석 기획



### 통계분석 개요

#### Population, Parameter, Sample, Statistic

모집단(popularion), 모수(parameter) <--> 표본(sample), 통계량(statistic)

* 모집단
  * 잘 정의된 연구목적과 이와 연계된 명확한 연구대상(데이터 전체 집합)
  * 예) 대통령 후보의 지지율 - 유권자
* 모수
  * 모집단의 특성을 나타내는 수치들
  * 모집단의 평균(μ), 분산(σ^2) 같은 수치들을 모수(parameter) 라고 함

* 표본
  * 모집단의 개체 수가 많아 전부 조사하기 힘들 때 모집단에서 추출(sampling) 한 것
  * 추출(sampling)한 표본으로 모집단의 특성을 추론(inference) 함(오차 발생)
  * 예) 각종 여론조사에 참여한 유권자
* 통계량
  * **표본의 특성을 나타내는 수치들**
  * 표본의 평균(x̄), 분산(s^2)같은 수치를 통계량(statistic)이라고 함



### 표본추출

#### 확률적 표본추출법의 종류

* 단순 무작위 추출(Simple random sampling)
  * 모집단의 각 개체가 표본으로 선택될 확률이 동일하게 추출되는 경우
  * 모집단의 개채 수 N, 표본 수 n 일 때 개별 개체가 선택될 확률은 n/N임
* 계통추출(Systematic sampling)
  * 모집단 개체에 1, 2, ... , N 이라는 일련번호를 부여한 후, 첫번째 표본을 임의로 선택하고 일정 간격으로 다음 표본을 선택함
  * 1~100 번호 부여 후, 10개 선택한다면, [1, 11, 21, 31, ... , 91] 선택
* **층화추출(Stattified sampling)**
  * 모집단을 **서로 겹치지 않게 몇 개의 집단 또는 층(strata)** 으로 나누고, 각 집단 내에서 원하는 크기의 표본을 단순 무작위추출법으로 추출함
  * 층 : 성별, 나이대, 지역 등 차이가 존재하는 그룹
* 군집추출(Cluster sampling)
  * 모집단을 **차이가 없는 여러 개의 집단(cluster)** 로 나눔 (예) 경상대학 내의 경영학과 경제학과
  * 이들 집단 중 몇 개를 선택 한 후, 선택된 집단 내에서 필요한 만큼의 표본을 임으로 선택함

비확률 표본 추출법은 특정 표본이 선정될 확률을 알 수 없어 통계학에서 사용할 수 없음



### 척도의 종류

* 명목척도 nominal scale
  * 단순히 측정 대상의 **특성을 분류하거나 확인**하기 위한 목적
  * 숫자로 바꾸어도 그 값이 크고 작음을 나타내지 않고 범주를 표시함
  * 성별, 혈액형, 출생지 등
* 서열(순위) 척도 ordinal scale
  * 대소 또는 높고 낮음 등의 **순위만 제공할 뿐 양적인 비교는 할 수 없음**
  * 항목들 간에 서열이나 순위가 존재
  * 금, 은, 동메달, 선호도, 만족도 등
* 등간척도(구간척도) interval scale
  * **순위를 부여하되 순위 사이의 간격이 동일** 하여 **양적인 비교가 가능함**
  * **절대 0점이 존재하지 않음**, 온도계 수치, 물가지수
* 비율척도 ratio scale
  * **절대 0점이 존재** 하여 측정값 사이의 비율 계산이 가능한 척도
  * 몸무게, 나이, 형제의 수, 직장까지 거리



### 집중화 경향 측정

#### 집중화 경향(central tendency) 측정에 사용되는 값들

* 평균(mean) : 값 들의 무게 중심이 어디인지를 나타내는 값, 산술 평균
* 중앙값(median) : 자료를 크기 순서대로 배열했을 때, 중앙에 위치하게 되는 값
* 최빈값(Mode) : 어떤 값이 가장 많이 관찰되는지 나타낸 값



### 데이터의 퍼짐 정도 측정

#### 데이터 집합이 얼마나 퍼져 있는지를 알아보는데 사용하는 값들

* 산포도(dispersion)
  * 자료의 변량들이 흩어져 있는 정도를 하나의 수로 나타낸 값
  * **산포도가 크면 변량들이 평균으로부터 멀리 흩어져 있음, 변동성이 커짐**
  * **산포도가 작으면 변량들이 평균 주위에 밀집, 변동성이 작아짐**
  * 범위, 사분위수 범위, 분산, 표준 편차, 절대 편차, 변동 계수
* 편차
  * **어떤 자료의 변량에서 평균을 뺀 값** 을 편차라고 한다(편차 = 변량 - 평균)
  * **편차의 총합은 항상 0**, 편차의 절댓값이 클수록 그 변량은 평균에서 멀리 떨어져 있고, 편차의 절댓값이 작을수록 평균에 가까이 있다.
* 분산(s^2) variance
  * 편차의 제곱의 합을 n-1로 나눈 것
  * 데이터 집합이 얼마나 퍼져 있느느지 알아볼 수 있는 수치
  * 평균이 같아도 분산은 다를 수 있음
* 표준편차(s) standard deviation
  * 자료의 산포도를 나타내는 수치, 분산의 양의 제곱근
  * 평균으로부터 각 데이터의 관찰 값까지의 평균거리

### 분산, 표준편차

#### 분산, 표준편차의 이해

* 특정도시의 10가구를 표본으로 추출해 자녀수를 조사한 겨로가가 0, 0, 0, 1, 1, 2, 2, 3, 3, 3 일때
* 표본 평균 : 1.5, 표본 분산 : 1.61, 표본 표준편차 : 1.27이 나옴
* 특정도시의 각 가구는 평균 1.5명의 자녀를 가지고, 각 가구는 약 1.27명의 자녀를 더하거나 뺀 범위 안에 있을 것으로 예상



### 변동계수(cv, coefficient of variation)

* 단위가 다른 두 그룹 또는 단위는 같지만 평균차이가 클 때의 산포 비교에 사용함

  * A 학생이 평균 3시간 공부하고 표준편차는 0.4였고, B 학생은 평균 6시간 공부하고 표준편차가 0.9였다면 어떤 학생이 꾸준하게 공부했을까?
  * cv = s/x   A = 0.4/3 = 0.133, B = 0.9/6 = 0.15 이므로 변동계수가 작은 A가 더 꾸준히 공부함
  * 이때 B학생의 표준편차가 0.8이라면 A,B학생의 변동계수가 같아짐, 즉 공부시간 평균에 대한 표준편차의 비율이 CV이다.
  * 관측되는 자료가 모두 양수일 때 사용

  

### 통계 기본 용어

* 표본점
  * 어떤 행위를 했을 때 나올 수 있는 값
  * 주사위를 굴릴떄 : 1, 2, 3, 4, 5, 6
* 표본공간
  * 모든 표본점의 집합
  * 주사위를 굴릴때 : S = {1, 2, 3, 4, 5, 6}
* 사건
  * 표본점의 특정한 집합
  * 주사위를 한 번 굴렸을 때 홀수가 나오는 사건을 A라고 한다면 A = {1, 3, 5}
* 확률
  * 사건이 일어날 수 있는 가능성을 수로 나타낸 것
  * 어떤 사건을 A라고 했을 때, A가 발생할 확률은 P(A)와 같이 표기함
  * 확률 = 사건 / 표본공간
  * 확률 값 : **0 <= P(A) <= 1**



### 사건의 종류

* 독립사건
  * A의 발생이 B가 발생할 확률을 바꾸지 않는 사건
  * 두 사건 A,B가 독립이면 P(B|A) = P(B), P(A|B) = P(A), P(A and B) = P(A)*P(B) 성립
  * 예) 주사위 던져서 나오는 눈의 값과 동전을 던져 나오는 앞/뒤 사건
  * 예) 서로 다른 사람이 총을 쏘아 과녁에 명중할 사건
* 배반사건
  * **교집합이 공집합**인 사건, 한쪽이 일어나면 다른 쪽이 일어나지 않을 때의 두 사건
  * P(A and B) = 0, P(A or B) = P(A) + P(B)
* 종속사건
  * 두 사건 A, B에서 한 사건의 결과가 다른 사건에 영향을 주는 사건
  * 예) 음주와 사고 사건, P(A and B) = P(A|B) * P(B)



### 조건부확률

* 조건부확률(conditional probability)
  * 사건 B가 발생했다는 조건 아래서 사건 A가 발생할 조건부 확률
  * **P(A|B) = P(A and B) / P(B), 단 P(B) > 0**
  * 두 사건 A, B가 **독립사건인 경우 : P(B|A) = P(B), P(A|B) = P(A), P(A and B) = P(A)*P(B)**



### 확률분포

* 분포
  * 일정한 범위 안에 흩어져 있는 정도
* 확률변수
  * random variable, 확률 현상에 기인해 결과값이 확률적으로 정해지는 변수
  * 확률 현상 : 어떤 결과들이 나올지 알지만, 가능한 결과들 중 어떤 결과가 나올지 모르는 현상
* 확률분포
  * 어떤 확률변수가 취할 수 있는 모든 값들과 그 값을 취할 확률의 대응관계로 표시하는 것
* 이산형 확률분포
  * Discrete(별개의), 확률변수가 몇개의 한정된 가능한 값을 가지는 분포
  * 각 사건은 서로 독립이어야 함
  * **예) 이항분포, 베르누이분포, 기하분포, 포아송분포 등**
* 연속형 확률분포
  * Continuous, 확률변수의 가능한 값이 무한 개이며 사실상 셀 수 없을 때
  * 예) 정규분포, 지수분포, 연속균일분포, 카이제곱분포, F분포 등



### 이산형 확률분포

* 베르누이분포
  * 실험 결과 두 가지 중의 하나로 나오는 시행의 결과를 0 또는 1 값으로 대응시키는 확률변수 X에 대해 아래 식을 만족하는 확률변수 X가 따르는 확률분포
  * P(X=0) = p, P(X = 1) = q, 0<=p<=1, q = 1 - p
  * 예) 동전을 던져서 앞면이 나올 확률, 주사위를 던져서 4의 눈의 나올 확률
* 이항분포
  * 서로 독립된 **베르누이 시행을 n회 반복할 때** 성공한 횟수를 x라 하면, **성공한 x의 확률분포를 말함**
  * 확률변수 K가 n, p 두 개의 모수를 갖으며, K~B(n,p)로 표기함
  * n=1일때 이항분포가 베르누이 분포임
  * 이항분포의 기댓값 : E(x) = np
  * 이항분포의 분산 : V(x) = np(1-p)
  * 예) 동전을 50번 던져서 앞면이 나올 경우, 주사위를 10번 던져서 나오는 눈이 5일 경우
* 기하분포
  * **베르누이 시행에서 처음 성공까지 시도한 횟수 X의 분포**, 지지집합(x) = {1, 2, 3 ...}
  * 베르누이 시행에서 처음 성공할 때까지 실패한 횟수 Y = X - 1의 분포, 지지집합 (x) = {0, 1, 2, ... }
    * 성공 확률이 p인 베르누이 시행에 대해 x번 시행 후 첫 번째 성공을 얻을 확률, X ~ G(p)로 표기
    * P(X = x) = (1-p)^(x-1)p  (x = 1, 2, 3, ...)
    * 실패 횟수에 대해서는 P(Y = x) = (1-p)^(x)p  (x = 1, 2, 3, ...)
  * 예) A야구선수의 홈런 칠 확률이 5%일때, 이 선수가 x번째 타석에서 홈런 칠 확률
* 포아송분포(poisson distribution)
  * **단위 시간이나 단위 공간에서 어떤 사건이 몇 번 발생할 것인지를 표현하는 분포**
  * 특정 기간 동안 사건(event) 발생의 확률을 구할 때 쓰임
  * X ~ Pois(np)
  * λ : 정해진 시간 안에 어떤 사건이 일어날 횟수에 대한 기댓값, P(X = x) = (e^(-λ)*λ^x) / x!
  * 예) 어느 AS센터에 1시간당 평균 120건의 전화가 온다. 이때 1분동안 걸려오는 전화 요청이 4건 이하일 확률은?



### 기댓값

기댓값 : 확률변수 X의 가능한 모든 값들의 가중 평균

| 이산적 확률변수 기댓값 | E(X) = sum(x) * f(x)    |
| ---------------------- | ----------------------- |
| 연속적 확률변수 기댓값 | E(X) = integr(x) * f(x) |


### 연속형 확률분포 - 정규분포

* 정규분포 normal distribution
  * 가우스 분포라고도 하며, 수집된 자료의 분포를 근사하는데 자주 사용함
  * 평균과 표준편차(σ)에 대해 모양이 결정되고 N(μ, σ^2)로 표기함
  * 평균 0, 표준편차/분산 1인 정규분포, **N(0, 1)를 표준 정규 분포, z분포 라고 함**
  * 예) 키, 몸무게, 시험 점수 등 거의 대부분의 측정값이 정규분포를 따름
  * z분포의 평균 주위로 표준편차의 1배 범위에 있을 확률 68%, 2배 범위 안 95%, 3배 범위 안 99.7%
* 확률 밀도 함수 probability density function, PDF
  * 특정 구간에 속할 확률을 계산하기 위한 함수
  * 확률 밀도 함수, f(x)와 구간 [a,b]에 대해 확률변수 X가 구간에 포함될 확률P(a < X < b) = |_integr_{(a);(b);{f(x)dx}
  * 확률밀도 함수는 다음의 두 조건을 만족함
    1. 모든 실수 값 x에 대해 f(x) >= 0
    2. |_integr_{{-∞};{∞};{f({x})dx}}=1
* 3시그마 규칙
  * 약 68%의 값들이 평균에서 양쪽으로 1 표준편차 범위(μ±σ)에 존재
  * 약 95%의 값들이 평균에서 양쪽으로 2 표준편차 범위(μ±2σ)에 존재
  * 거의 모든 값들(99.7%)이 평균에서 양쪽으로 3표준편차 범위(μ±3σ)에 존재

### 연속형 확률분포 - 정규분포의 당위성

대부분의 측정값을 정규분포로 가정하는 이유 : 정규분포의 당위성

* 이항분포의 근사
  *  시행횟수 N이 커질때 ,이항분포 B(N, p)는 평균 Np, 분산 Npq인 정규분포와 N(Np, Npq)와 거의 같아짐
* 중심 극한 정리
  * 표본의 크기가 N인 확률표본의 **표본평균**은 **N이 충분히 크면** 근사적으로 **정규분포** 를 따르게 됨
  * **모집단의 분포와 상관없이** 표본의 크기가 30이상이 되면 N이 커짐에 따라 표본평균의 분포가 정규분포에 근사해짐
* 오차의 법칙
  * 오차(error) : ε = x - μ
  * MLE(Maximum Likelihood Estimator) : 실제 값일 가능성이 가장 높은 값
  * 실제 값의 MLE가 측정값의 평균이라면, 오차는 정규분포를 따른다 -> 오차의 법칙

### 연속형 확률분포 - 균등분포(uniform distribution)

* 이산균등분포
  * 확률분포함수가 정의된 모든 곳에서 값이 일정한 분포
  * 확률변수가 n개의 값을 가질 수 있다면, ki일 확률이 1/n임 (예: 주사위 던지기)
* 연속균등분포
  * 연속확률분포로 분포가 특정 범위 내에서 균등하게 나타나 있을 경우
  * 두 개의 매개변수 a, b를 받으며, [a, b] 범위에서 균등한 확률을 가짐
  * u(a, b)로 나타내며, u(0, 1)인 경우 표준연속균등분포 라고 함

### 연속형 확률분포 - 지수분포(exponential distribution)

* 지수분포
  * 사건이 서로 독립적일 때 **다음 사건이 일어날 때까지 대기 시간** 은 지수분포를 따름
  * 일정 시간 동안 발생하는 사건의 횟수는 포아송 분포를 따름
  * 지수분포와 포아송분포는 λ를 사용함



### 연속형 확률분포 - t-분포

* t-분포
  * 정규분포는 표본의 수가 적으면 신뢰도가 낮아짐(n이 30개 미만인 경우)
  * **표본을 많이 뽑지 못하는 경우에 대한 대응책** 으로 예측범위가 넓은 분포를 사용하며, 이것이 t-분포이다.
  * t-분포는 표본의 개수에 따라 그래프의 모양이 변함
    * 표본의 개수가 많아질 수록 정규분포와 비슷하며, 적을수록 옆으로 퍼짐
    * 표본의 개수가 적을수록 신뢰도가 낮아지기 때문에 예측 범위를 넓히기 위해 옆으로 퍼지게 됨
  * t-분포는 표본의 수가 30개 미만일 때 사용하며, '신뢰구간', '가설검정' 에 사용함
  * 그래프 x축 좌표를 t값이라 부르며, t분포표를 사용해 구하고 검정에 사용함

### 연속형 확률분포 - 카이제곱 분포(x^2)

* **분산의 특징을 확률분포로 만든 것** 으로, 카이(x)는 평균 0, 분산 1인 표준정규포를 의미함
* 카이제곱(x^2)은 표준정규분포를 제곱한다는 의미가 내포되어 있음
* 자유도(df, 미지수의개수) v인 카이제곱분포를 v개 합한것의 분포
* X1, X2, ... Xv 가 표준정규분포를 따를 때 Q = X1^2 + X2^2 + ... + Xv^2  Q~X^2(v)
* X^2(v)의 평균 : v, 분산 : 2v
* 신뢰구간, 가설검정에 사용하며, 그래프의 x축 좌표를 카이제곱값이라 부르며, 카이제곱분포표를 사용해 구하고 검정에 사용함
* 0이상의 값만 가질 수 있으며, 오른쪽 꼬리가 긴 비대칭 모양
* 0의 오른쪽 부분에 분포가 많고, 0에서 멀어질 수록 분포 감소
* 표본의 수가 많아지면 옆으로 넓적한 정규분포 형태가 됨
* 카이제곱분포의 특징이 곧 분산(치우침정도)의 특징임

### 연속형 확률분포 - F분포

* F 분포
  * 카이제곱분포와 같이 **분산**을 다룰때 사용하는 분포
  * 카이제곱분포는 한 집단의 분산, **F분포는 두집단의 분산을 다룸**
  * **두 집단의 분산의 크기가 서로 같은지 또는 다른지 비교하는데 사용함**
    * 보통 나눗셈을 활용해 두 집단의 분산을 비교함, 나누었을 때 1 이면 두 집단의 크기가 같음으로 판단
  * 카이제곱과 비슷하게 대칭 모양이며, 양수만 존재함
  * 두 분산의 나눗셈을 확률분포로 나타낸 것이 바로 F분포임
  * 표본의 수가 많아지면 1을 중심으로 정규분포 모양이 됨
  * 분산 분석에 F분포를 사용하며, 그래프 x축 좌표인 F값을 활용하는데 F분포표를 사용해 구함

### 연속형 확률분포의 선택

1. 정규분포
2. 표준정규분포 : 정규분포를 표준화 / n이 작고 분산을 모를때 -> t-분포 / 분산을 알때 -> 카이제곱분포
3. 카이제곱 분포 : 표준정규 분포의 제곱의 합을 이용해 구함 / 한 집단의 분산일때 사용
4. F분포 : 카이제곱 분포 비 를 이용 / 두 집단의 분산일때 사용



### 통계적 추론의 분류

#### 모집단에 대한 가정 여부에 따른 통계적 추론의 분류

* 모수적 추론
  * Parametric Inference, 모집단에 특정 분포를 가정하고 모수에 대해 추론함
* 비모수적 추론
  * Non-parametric Ingerence, 모집단에 대해 특정 분포 가정하지 않음

#### 추론 목적에 다른 통계적 추론의 분류

* 추정 : Estimation, 통계량을 사용하여 모집단의 모수를 구체적으로 추측하는 과정
  * 점추정 Point estimation : 하나의 값으로 모수의 값이 얼마인지 추측함
  * 구간 추정 Interval estimation : 모수를 포함할 것으로 기대되는 구간을 확률적으로 구함
* 가설검정 Testing hypotheses : 모수에 대한 가설을 세우고 그 가설의 옳고 그름을 확률적으로 판정하는 방법론

#### 모수처리 방식에 따른 통계적 추론의 분류

* Frequentist
* Bayesian



### 표준편차

* 표준편차 Standard Deviation
  * 자료가 평균을 중심으로 얼마나 퍼져 있는지를 나타내는 대표적 수치
  * 편차 (관측값 - 평균)

### 표준오차

* 표준편차 
  * 한 표본에서 전체 개체가 가지는 값들의 차이가 얼마나 큰지 나타냄
* 표준오차 Standard Error
  * 표본 집단의 평균값이 실제 모집단의 평균값과 얼마나 차이가 있는지 나타냄
  * 오차(추정값 - 참값)
  * 모집단에서 샘플을 무한 번 뽑아서 **각 샘플마다 평균** 을 구했을 때, 그 **평균들의 표준편차** 를 표준오차라 할 수 있음
  * 표본평균이 모평균과 얼마나 떨어져 있는가를 나타냄, n이 클수록 작은 값
  * 모평균에 대해 추론할 때 표본평균의 표준오차를 사용함
  * SE(Standard Error) = 원시데이터의 표준편차 / (평균값 계산에 사용한 데이터 수)^0.5 = σ/n^0.5

### 표본오차

* 표본오차 Sampling Error
  * 표본을 샘플링 할 때, 모집단을 대표할 수 있는 전형적인 구성 요소를 선택하지 못함으로써 발생하는 오차
  * 표본의 크기를 증가시키고, 표본 선택 방법을 엄격히 하여 줄일 수 있음
* 오차한계
  * 추정을 할때 모평균 추정구간의 중심으로부터 최대한 허용할 최대 허용 오차
  * 추정 문제에서 표본오차를 구하라는 것은 '오차한계'를 구하라는 것과 같은
  * 오차한계는 임계값(critical value)와 표준오차(SE)를 곱한 값
  * 임계값 : 표준정규분포에서는 z값, t분포에서 t값, 카이제곱분포에서는 카이제곱값
  * 표본오차 = 오차한계 = 임계값 * σ/n^0.5
  * **표준정규분포에서 표본오차 = z * σ/n^0.5 **



### 추정량(estimator)

추정이란 표본의 통계량(평균, 분산, 표준편차)를 가지고 모집단의 모수를 추측하여 결정하는 것

* 추정량 (estimator) : 모수를 추정하기 위한 관찰 가능한 표본의 식 또는 표본함수
* 추정값 (estimate) : 표본의 식 또는 한수에 실제 관찰치를 대입하여 계산한 값

#### 좋은 추정량 판단 기준

* 일치성(consistency)
  * 표본의 크기가 커짐에 따라 표본 오차가 작아져야 한다.

* 비편향성, 불편성(unvbiasedness) 
  * 편향(bias) = 추정량의 기댓값 = 실제값(=모수의 값) = E(θ) - θ
  * 추정량의 기댓값이 모수의 값과 같아야 한다(편향 == 0)
* 효율성(efficiency)
  * 추정량의 분산이 될 수 있는 대로 작아야 한다(최소분산 추정량)
  * MSE(Mean Square Error)가 작아야 한다.

### 통계적 추정(Estimation) - 점추정

* 점추정
  * Point estimation, 통계량 하나를 구하고 그것을 가지고 모수를 추정하는 방법
  * '모수가 특정한 값일 것' 이라고 추정하는 것
  * A과목 수강 전체 학생 중 50명을 뽑아 조사한 결과 기말점수가 80점 이었다면, 50명 뿐 아니라 나머지 A과목을 수강한 학생들의 점수도 80점 정도로 추정하는 것
* 점추정량 구하는 법
  * 적률법 - 표본의 기댓값을 통해 모수를 추정하는 방법
  * 최대가능도추정법(최대우도법) - 함수를 미분해서 기울기가 0인 위치에 존재하는 MLE(maximum likelihood estimator)를 찾는 방법
  * 최소제곱법 - 함수값과 측정값의 차이인 오차를 제곱한 합이 최고가 되는 함수를 구하는 방법

### 통계적 추정(Estimation) - 구간추정

* 구간추정
  * interval estimation, 점추정의 정확성을 보완하는 방법
  * 통계량을 제시하는 것은 같지만 신뢰구간을 만들어서 추정하는 것
* 신뢰구간
  * 모수가 포함되라라고 기대되는 '범위'
* 신뢰수준
  * 모수값이 정해져 있을때 다수 신뢰구가 중 **모수값을 포함**하는 신뢰구간이 존재할 확률
  * 신뢰수준 95% 의미 : n번 반복 추출하여 산정하는 신뢰구간들 중에서 평균적으로 95%는 모수 값을 포함하고 있을 것이라는 의미
  * 신뢰수분 95%에서 투표자의 35%~45%가 A후보를 지지하고 있다. -> 95%는 신뢰수준, 35~45%는 신뢰구간이다.



### 가설검정

* 가설검정 statistical hypothesis testing
  * 모집단에 대한 어떤 가설을 설정한 뒤에 표본관찰을 통해 그 가설의 채택 여부를 결정하는 통계적 추론 방법
* 귀무가설(H0) null hypothesis
  * 가설검정의 대상이 되는 가설, 연구자가 **부정사고자 하는 가설**
  * 설정한 가설이 진실할 확률이 극히 적어 처음부터 버릴 것(기각)이 예상되는 가설
* 대립가설(H1) anti hypothesis
  * 귀무가설이 기각될 때 받아들여지는 가설
  * **연구자가 연구를 통해 입증 또는 증명되기를 기대하는 예상이나 주장**
* 기각역 critical region
  * 검정통계량(t-value)의 분포에서 유의수준의 크기에 해당하는 영역
  * 계산한 검정통계량의 유의성(귀무가설의 기각)을 판정하는 기중

범죄사건에서 용의자가 있을때 형사의 가설

* 귀무가설 : 용의자는 무죄이다
* 대립가설 : 용의자가 범죄를 저질렀다.

성적 관련 선생님의 가설

* 귀무가설 : 남학생과 여학생의 평균은 같다
* 대립가설 : 남학생과 여학생의 평균은 다르다



### 오류

* 제 1종 오류 : α error, 귀무가설이 **참인데 기각**하게 되는 오류
* 제 2종 오류 : β error, 귀무가설이 **거짓인데 채택** 하는 오류
  * 두가지 오류가 작을수록 바람직함
  * 두가지를 동시에 줄일 수 없기 때문에 1종오류를 범할 확률의 최대 허용치를 미리 어떤 특정값(유의수준)으로 지정해 놓고 제 2종 오류의 확률을 가장 작게 해주는 검정 방법을 사용함
* 유의수준(α)
  * significance level, **제 1종 오류의 최대 허용 한계**
  * 유의수준 **0.05(5%)** : 100번 실험에서 1종오류 범하는 최대 허용 한계가 5번
* 유의 확률 = p-value
  * probability value, 0 ≤ p-value ≤ 1, **1종 오류를 범할 확률**, 귀무가설을 지지하는 정도
  * 귀무가설이 사실일 때 기각하는 1종 오류 시 **우리가 내린 판정이 잘못되었을 확률**
  * 검정 통계량들은 거의 대부분이 귀무가설을 가정하고 얻게되는 값
  * 검정 통계량에 관한 확률로, 극단적인 표본 값이 나올 확률
  * p-value가 작을 수록 그 정도가 약하다고 보며, **p-value < α 귀무가설을 기각, 대립가설을 채택** 함
  * p-value 가 0.05(5%) : 귀무가설을 기각했을 때 기각 결정이 잘못될 확률이 5%임

#### 귀무가설을 이용한 가설검증 프로세스

귀무가설, 대립가설 가정 -> 실험 수행 -> 귀무가설로 결과 해석 불가 -> 대립가설 채택

유의수준은 일반적으로 0.05설정



### 모수적, 비모수적 추론

* 모수적 추론
  * **모집단에 특정 분포를 가정**하고 분포의 특성을 결정하는 **모수에 대해 추론하는 방법**
  * 모수로는 평균, 분산 등을 사용
  * 자료가 정규분포, **등간척도, 비율척도** 인 경우(온도, 물가지수, 몸무게, 자녀수 ...)
* 비모수적 추론
  * **모집단에 대해 특정 분포 가정을 하지 않음**
  * 모수 자체보다 **분포 형태에 관한 검정**을 실시함
  * **표본 수가 적고, 명목척도, 서열척도**인 경우(성별, 혈액형, 만족도, 배달)



### 모수적 추론(inference)

* 모수적 검정
  * 검정하고자 하는 모집단의 분포에 대해 가정을 하고, 그 가정하에서 검정 통계량과 검정 통계량의 분포를 유도해 검정을 실시함
    1) 가정된 분포의 모수에 대해 가설 설정
    2) 관측된 자료를 이용해 구한 표본 평균, 표본 분산 등을 이용해 검정 실시
* 모수적 통계의 전제조건
  * 표본의 모집단이 **정규분포**를 이루어야 하며, 집단 내의 **분산은 같아야 함**
  * 변인(=변수)은 **등간척도나 비율척도로 측정**되어야 함(아니면 비모수 통계 사용)
* 모수 검정방법
  * T test, Pair T test, ANOVA test, z분포, t분포, F분포, 카이스쿼어 분포
* 모수 검정방법 사용 예
  * 모평균과 표본평균과의 차이 : z분포, t분포
  * 표본평균간의 차이 : z분포, t분포
  * 모분산과 표본분산과의 차이 : F분포, 카이제곱(=스카이스쿼어)분포
  * 표본분산 간의 차이 : F 분포, 카이제곱분포



### 모수적 추론 : T-test

* T test
  * **평균**값이 올바른지, 두 집단의 **평균 차이**가 있는지를 검증하는 방법으로 t값을 사용함
  * t값이 커지수록 p-value는 작아지며, 집단간 유의한 차이를 보일 가능성이 높아짐

|              t-검정 방법               | 예시                                                         |
| :------------------------------------: | ------------------------------------------------------------ |
|           One Sample t-test            | * 단일 표본의 평균 검정을 위한 방법<br />* S사 USB의 평균 수명은 20000시간이다 |
|   Paired t-test<br />대응표본 t-검정   | * **동일 개체에 어떤 처리를 하기 전, 후의 자료를 얻을 때** 차이값에 대한 평균 검정을 위한 방법<br />* 예) 매일 1시간 한달 걸으면 2kg이 빠진다(걷기 수행 정/후)<br />* **가능한 동일한 특성을 갖는 두 개체에 서로다른 처리**를 하여 그 처리의 효과를 비교하는 방법(matching)<br />* 예) X질병 환자들을 두 집단으로 나누어 A, B약을 투약해 약의 효과 비교 |
| Two sample t-test<br />독립표본 t-검정 | * **서로다른 두 그룹**의 평균을 비교하여 두 표본의 차이가 있는지 검정하는 방법<br />* 귀무가설 - 두 집단의 평균 차이값이 0이다.<br />* 2학년과 3학년의 결석률은 같다 |



### 자유도(Degree of freedom)

* 자유도
  * 통계적 추정에서 표본자료 중 모집단에 대한 정보를 주는 독립적인 자료의 수
  * n개 데이터를 이용해 어떤 통계량 A를 계산하고자 할 때 필요한 다른 통계량 B가 있다면 B는 A를 계산하기 전에 고정된 값을 가져야 하고 이것이 자유도에서 제외된다.
  * 다른 통계량을 한 개 사용한 크기가 n인 표본의 자유도 : n-1, 관측값(x1, x2, ... xn)
  * 표본 평균에서의 자유도 : n / 표본 분산에서 자유도 : n-1

예) 1 3 5 7 9 데이터는 합계가 25이고 평균이 4이다.

이때, 숫자 하나를 모르더라도 평균을 알면 그 숫자를 찾아낼 수 있따.

즉 표본 평균 값을 알고있으면 전체 자료 중 자유롭게 값을 취할 수 있는 관찰치의 개수는 4개이다.



### 데이터의 정규성 검정

데이터의 정규성 검정 종류 : Q-Q plot, Histogram, Shapiro Wilk test

* Q - Q plot
  * 그래프를 그려서 정규성 가정이 만족되는지 **시각적으로 확인하는 방법**
  * 대각선 참조선을 따라 값들이 분포하게 되면 정규성을 만족한다고 할 수 있음
* Histogram
  * 구간별 돗수를 그래프로 표시하여 **시각적으로 정규분포를 확인**하는 방법
* Shapiro-Wilk test
  * 오차항이 정규분포를 따르는지 알아보는 검정
  * 귀무가설은 정규분포를 따른다로 p-value가 0.05보다 크면 정규성을 가정하게 됨
  * 회귀분석에서 모든 독립변수에 대해 종속변수가 정규분포를 따르는지 알아보는 방법
* kolmogorov-Smirnov test
  * K-S test, 두 모집단의 분포가 같은지 검정하는 것
  * **p-value가 0.05보다 크면 정규성을 가정**하게 됨



### 비모수적 추론(inference)

* 비모수적 검정
  * 모집단의 분포에 대해 제약을 가하지 않고 검정을 실시하는 검정 방법
  * 모수 자체보다 **분포 형태에 관한 검정**을 실시함
  * 가설을 '분포의 형태가 동일하다', '분포의 형태가 동일하지 않다'와 같이 분포 형태에 대해 설정함
  * 관측 값들의 순위나 두 관측 값 사이의 부호 등을 이용해 검정
  * 모집단의 특성을 몇 개의 모수로 결정하기 어려우며 **수 많은 모수가 필요할 수 있음**
  * **모수적 방법보다 훨씬 단순**함, 민감성ㅇ르 잃을 수 있음
* 비모수적 검정의 종류
  * 명목척도 기준 : **카이스쿼어 검정(Chi-square test)**, McNemar test, Cochran test
  * 서열척도 기준 : Kolmogorov-Smirnov test, **Sign Test**, Wilcoxon signed rank test, Friendman test, Mann-Whitney U test, Kruskal-Wallis H test

### 모수/비모수적 추론 방법

| 비교대상<br />집단수 |   관계   |   비모수-명목척도   |              비모수-서열척도              | 모수                 |
| :------------------: | :------: | :-----------------: | :---------------------------------------: | -------------------- |
|          1           |          | **카이스쿼어 검정** |          Kolmogorov-Smirnov test          | One sample T test    |
|          2           |   독립   |      Crosstab       |            Mann-Whitney U test            | Two sample T test    |
|                      | 대응자료 |    McNemar test     | Wilcoxon signed -rank test, **Sign test** | Paired T test        |
|      k(다변량)       |   독립   |                     |           Kruskal-Wallis H test           | ANOVA test(분산분석) |
|                      | 대응자료 |    Cochran test     |               Friedman test               |                      |

### 카이스쿼어, 부호 검정

* 카이스쿼어 검정
  * **한 개 범주형 변수**와 각 그룹별 비율과 특정 상수비가 같은지 검정하는 **적합도 검정**
  * 각 집단이 서로 유사한 성향을 갖는지 분석하는 **동질성 검정**
  * **두 개 범주형 변수**가 서로 독립인지 검정하는 **독립성 검정**
* 카이스쿼어 검정 가설 예
  * 적합도 검정(한 개 범주형 변수, 알려진 사실) : 교배 실험으로 얻은 완두콩 비율이 멘젤의 법칙 9:3:3:1을 따르는 지 검정으로, 기존에 알려진 기준이 존재
  * 동질성 검정(부모집단, 범주형 변수) : 부모집단(subpopulation)에 대해 열 변수의 분포가 동질한지 검정, 성별에 따라 음료 선호가 동질한지에 대한 검정
  * 독립성 검정(두 개 범주형 변수) : 도로형태(국도, 특별광역시도, 고속도로)와 교통사고 피해정도(사망, 중상, 경상)의 관련성 검정
* 부호 검정 Sign Test
  * 표본들이 서로 관련되어 있는 경우, 짝지어진 두 개의 관찰치들의 크고 작음을 +와 -로 표시하여 그 개수를 가지고 **두 그룹의 분포 차이가 있는가에 대한 가설을 검증**하는 방법
* 부호 검정 가설 예
  * 귀무가설 : 두 생산 라인의 일별 생산량 중 불량품 수의 분포는 동일하다.
  * 대립가설 : 두 생산 라인의 일별 생산량 중 불량품 수의 분포는 동일하지 않다.



### 회귀 분석(Regression Analysis)

* 독립변수
  * 다른 변수에 영향을 받지 않고 독립적으로 변화하는 수, 설명 변수라고도 함
  * 입력 값이나 원인을 나타내는 변수, **y = f(x)에서 x 에 해당**하는 것
* 종속변수
  * 독립변수의 영향을 받아 값이 변화하는 수, 분석의 대상이 되는 변수
  * 결과물이나 효과를 나타내는 변수, **y = f(x)에서 y에 해당**하는 것
* 잔차(오차항)
  * 계산에 의해 얻어진 이론 값과 실제 관측이나 측정에 의해 얻어진 값의 차이
  * 오차(Error) - 모집단, 잔차(Residual) - 표본집단



#### 회귀분석

* 변수와 변수 사이의 관계를 알아보기 위한 통계적 분석 방법
* 독립변수의 값에 의해 종속변수의 값을 예측하기 위함
* 일반 선형회귀는 종속변수가 **연속형 변수일 때 가능함**
* 이산형 - 명목, 서열척도, 연속형 - 구간, 비율척도



### 선형회귀 모형(linear regression)

* 선형 회위
  * 종속변수 y와 한 개 이상의 독립변수 X와의 선형 상관 관계를 모델링하는 회귀분석 기법
  * 한 개의 독립변수 : 단순 선형 회귀, 둘 이상의 독립변수 : 다중 선형 회귀
* 단순 선형 회귀 모형(독립변수 1개일 때)
  * **모집단**
    * Yi = β0 + β1Xi + εi     i = 1, 2, ... , n
    * Yi : i번째 종속변수
    * Xi : i번째 독립변수
    * εi : 오차(error)
    * β0 : 선형회귀식의 절편
    * β1 : 기울기, 회귀계수(coefficient)



### 단순선형회귀분석 - 최소자승법

* 최소자승법(Least Square Method)

  * **Y = f(X)의 측정값 yi와 함수값 f(xi)의 차이를 제곱한것의 합이 최소가 되도록 Y=f(X)를 구하는 것**
  * **Y = aX + b일 때 잔차를 제곱한 것의 합이 최소가 되도록 하는 상수 a, b를 찾는 것
  * 즉, (측정값 - 함수값)^2 의 합이 최소가 되는 직선의 그래프를 찾는 것
  * **큰 폭의 잔차에 대해 보다 더 큰 가중치를 부여**하여, 독립변수 값이 동일한 병균치를 갖는 경우 가능한 한 변동 폭이 적은 표본회귀선을 도출하기 위한 것

* 단일회귀 모형의 예

  set.seed(2)

  x = runif(50, 0, 5)

  y = 5  + 2 * x + rnorm(50 ,0, 0.5)

  df <- data.frame(x, y)

  fit <- lm(y~x, data=df)

  fit

Call :

lm(formula = y ~ x, data = dfrm)

Coefficients:                           x

(Intercept)    4.743(절편)    2.072(회귀계수)

- runif(개수, 시작, 끝) : 시작 ~ 끝 범위에서 개수 만큼의 균일분포를 따르는 난수 발생
- rnorm(개수, 평균, 표준편차) : 특정 평균 및 표준편차를 갖으며 정규분포를 따르는 난수 발생. 평균, 표준편차 생략시 평균 0, 표준편차 1
- **lm(y~x, data = df)** : df에서 y를 종속변수, x를 독립변수로 회귀 모형 생성



* 다중 회귀 모형의 예

  set.seed(10)

  u <- runif(50, 0, 6)

  v <- runif(50, 6, 12)

  w <- runif(50, 3, 25)

  y = 3 + 0.5 * u + 1 * v - 2*w + rnorm(50, 0, 0.5)

  df <- data.frame(y, u, v, w)

​		> a <- lm(y~u+v+w, df)

​		> a

Call:

lm(formula = y ~ u + v + w, data = df)

Coefficients:

(Intercept)                 u              v             w

​         3.4374(절편)  0.4676   0.9556   -1.9923     -> 회귀 계수

회귀 방정실 : y = 3.4374 + 0.4674*u +



### 회귀 모형의 가정

* 회귀 모형의 가정
  * 선형성 : 독립변수의 변화에 따라 종속변수도 변화하는 **선형(linear) 모형**이다
  * 독립성 잔차와 **독립변수의 값이 관련되어 있지 않다** (Durbin-Watson통계량 확인)
  * 정규성: 잔차항이 **정규분포** 를 이루어야 한다.
  * 등분산성 : 잔차항들의 분포는 **동일한 분산** 을 갖는다.
  * 비상관성 : 잔차들끼리 **상관이 없어야** 한다.
* Normal Q-Q plot
  * **정규성(정상성)**, 잔차가 정규분포를 잘 따르고 있는지를 확인하는 그래프
  * 잔차들이 그래프 선상에 있어야 이상적임
* Scale-Location
  * **등분산성**, y축이 표준화 잔차를 나타내며, 기울기 0인 직선이 이상적임
* Cook's Distance
  * 일반적으로 1값이 넘어가면 관측치를 영향점(influence points)로 판별

data(cars)

m < - lm(dist~speen, cars)

summary(m)

par(mfrow=c(2,2))

plot(m)

par(mflow=c(1,1))

y축은 잔차, 선형회귀에서 오차는 평균이 0이고 **분산이 일정한 정규분포를 가정**하므로 y값은 기울기가 0인 직선이 이상적임



### 회귀모형 해석(평가방법)

* 표본 회귀선의 유의성 검정
  * 두 변수 사이에 선형관계가 성립하는지 검정하는 것으로 회귀식의 **기울기계수 β1=0일 때 귀무가설, β1≠0일때 대립가설로 설정**한다.
* 회귀 모형 해석
  * 모형이 통계적으로 유의미한가? >> F 통계량, 유의확률(p-value)로 확인
  * 회귀 계수들이 유의미한가? >> 회귀계수의 t값, 유의확률(p-value)로 확인
  * 모형이 얼마나 설명력을 갖는가? >> 결정계수(R^2)확인
  * 모형이 데이터를 잘 적합하고 있는가? >> 잔차 통계량 확인, 회귀진단 진행(선형성 ~ 정상성)
* F 통계량, p-value
  * **F통계량 = 회귀제곱평균(MSR) / 잔차제곱평균(MSE)**
  * F통계량에 대한 p-value < 0.05
* t값, p-value
  * **t 값 = Estimate(회귀계수) / Std.Error(표준오차)**
  * t 값에 대한 p-value < 0.05
* 결정계수(R^2)
  * 70~90%

* F 통계량
  * 모델의 **통계적 유의성을 검정**하기 위한 검정 통계량(분산 분석)
  * F통계량 = 회귀제곱평균(MSA) / 잔차제곱평균(MSE)
  * F통계량이 클수록 회귀모형은 통계적으로 유의하다, p-value < 0.05 일 때 유의함
* 결정계수(R^2 = SSR/SST)
  * **회귀식의 적합도** 를 재는 척도
  * 결정계수(R^2) = 회귀제곱합(SSR) / 총제곱합(SST), 1 - (SSE/SST)
  * 결정계수는 0~1사이의 범위를 갖음
  * 전체 분산 중 모델에 의해 설명되는 분산의 양
  * 결정계수가 커질수록 회귀방정식의 설명력이 높아짐
    * SST : Total Sum of Squares, Y의 변동성
    * SSE : Error Sum of Squares, X,Y를 통해 설명하지 못하는 변동성
    * SSR : Regression Sum of Squares, Y를 설명하는 X의 변동성



### 다중 공선성

* 다중공선선(multicollinearity)
  * 모형의 일부 설명변수(=독립변수)가 다른 설명변수와 상관되어 있을 때 발생하는 조건
  * 중대한 다중공선성은 **회귀계수의 분산을 증가** 시켜 불안정하고 해석하기 어렵게 만들기 때문에 문제가 됨
  * R 의 vif함수를 사용해 구할 수 있으며, VIF값이 10이 넘으면 다중공선성이 존재한다고 봄
* 해결방법
  * 높은 상관 관계가 있는 설명변수를 모형에서 제거하는 것으로 해결함
  * 설명변수를 제거하면 대부분 R-square가 감소함
  * 단계적 회귀분석을 이용하여 제거함
* 설명변수의 선택 원칙
  * y에 영향을 미칠 수 있는 모든 설명변수 x들은 y의 값을 예측하는데 참여시킴
  * 설명변수 x들의 수가 많아지면 관리에 많은 노력이 요구되므로 가능한 범위 내에서 적은 수의 설명변수를 포함시켜야 함
  * 두 원칙이 이율배반적이므로 적절한 설명변수 선택이 필요함



### 설명 변수 선택 방법

* 모든 가능한 조합
  * **모든 가능한 독립변수들의 조합에 대한 회귀모형을 고려** 해 AIC, BIC의 기준으로 가장 적합한 회귀 모형 선택
  * AIC, BIC : 최소자승법의 R^2와 비슷한 역할을 하며, 적합성을 측정해주는 지표로, R^2는 큰값이 좋지만 **AIC, BIC는 작은값이 좋음**
* 후진제거법
  * Backward Elimination, **독립변수 후보 모두를 포함한 모형에서 출발**해 제곱합의 기준으로 가장적은 영향을 주는 변수로부터 **하나씩 제거**하면서 더 이상 유의하지 않은 변수가 없을 때까지 설명변수를 제거하고, 이때 모형을 선택
* 전진선택법
  * Forward Selection, **절편만 있는 모델에서 출발** 해 기준 통계치를 가장 많이 개선시키는 **변수를 차례로 차가하는 방법**
* 단계별 선택법
  * Stepwise method, 모든 변수가 포함된 모델에서 출발해 기준 통계치에 가장 도움이 되지않는 변수를 삭제하거나, 모델에서 빠져있는 변수 중에서 기준 통계치를 가장 개선시키는 변수를 추가함
* 회귀모델에서 변수 선택을 위한 판단 기준
  * Cp, AIC, BIC 등이 있으며, 값이 작을 수록 좋음



### 과적합(Overfitting)

* 과적합의 문제와 해결방법
  * 주어진 샘플들의 설명변수와 종속변수의 관계를 필요이상 너무 자세하고 복잡하게 분석
  * 샘플에 심취한 모델로 새로운 데이터가 주어졌을 때 제대로 예측해내기 어려울 수 있음
  * 해결 방법으로 Feature 의 개수를 줄이거나, Regulatizarion을 수행하는 방법이 있음

### Regularization

* 정규화 개념
  * 베타(β)값에 제약(penalty)을 주어 모델에 변화를 주는 것
  * λ값은 정규화 모형을 조정하는 hyper parameter
  * **λ값은 클수록 제약이 많아져 적은 변수가 사용되고, 해석이 쉬워지지만 underfitting 됨**
  * λ값이 작아질수록 제약이 적어 많은 변수가 사용되고, 해석이 어려워지며 overfitting됨

### L1, L2, Norm

* norm
  * 선형대수하겡서 벡터의 크기(magnitude) 또는 길이(length)를 측정하는 방법
  * L1 norm(=Manhattan norm) : 벡터의 모든 성분의 절대값을 더함
  * L2 norm(=Euclidean norm) : 출발점에서 도착점까지의 거리를 직선거리로 측정함

### Regularized Linear Regression

* 라쏘(Lasso) 회귀 특징
  * **변수 선택이 가능**하며, 변수간 상관관계가 높으면 성능이 떨어짐
  * **L1 norm을 패널티를 가진 선형 회귀 방법, 회귀계수의 절댓값이 클수록 패널티 부여**
  * MSE가 최소가 되게 하는 w, b를 찾는 동시에 w의 절대값들의 합이 최소가 되게 해야함
  * **w의 모든 원소가 0이 되거나 0에 가깝게 되게 해야함 => 불필요 특성 제거**
  * 어떤 특성은 모델을 만들 때 사용되지 않게 됨
* 라쏘(Lasso) 회귀 장점
  * 제약 조건을 통해 일반화된 모형을 찾는다.
  * **가중치들이 0이 되게 함으로써 그에 해당하는 특성들을 제외해준다.**
  * 모델에서 가장 중요한 특성이 무엇인지 알게 되는 등 모델 해석력이 좋아딘다.
* Ridge 회귀 특성
  * **L2 norm을 사용**해 패널티를 주는 방식
  * **변수 선택이 불가능**, 변수간 상관관계가 높아도 좋은 성능
  * Lasso는 가중치들이 0이 되지만, **Ridge의 가중치들은 0에 가까워 질 뿐 0이 되지는 않음**
  * 특성이 많은데 특성의 중요도가 전체적으로 비슷하다면 Ridge가 좀 더 괜찮은 모델을 찾아줄 것이다.
* 엘라스틱넷 특성
  * L1, L2 norm regularization
  * 변수 선택 가능
  * 변수 간 상관관계를 반영한 정규화
